{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from ruptures import Pelt\n",
    "from ruptures.metrics import hausdorff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_kurento_names = [\n",
    "    \"loadtest-webrtc-final-kurento-2p-t3medium\",\n",
    "    \"loadtest-webrtc-final-kurento-2p-t3medium-2\",\n",
    "    \"loadtest-webrtc-final-kurento-2p-t3medium-wait\",\n",
    "    \"loadtest-webrtc-final-kurento-2p-t3medium-retry\",\n",
    "    \"loadtest-webrtc-final-kurento-5p-t3medium\",\n",
    "    \"loadtest-webrtc-final-kurento-5p-t3medium-2\",\n",
    "    \"loadtest-webrtc-final-kurento-5p-t3medium-wait\",\n",
    "    \"loadtest-webrtc-final-kurento-5p-t3medium-retry\",\n",
    "    \"loadtest-webrtc-final-kurento-8p-t3medium\",\n",
    "    \"loadtest-webrtc-final-kurento-8p-t3medium-2\",\n",
    "    \"loadtest-webrtc-final-kurento-8p-t3medium-wait\",\n",
    "    \"loadtest-webrtc-final-kurento-8p-t3medium-retry\",\n",
    "    \"loadtest-webrtc-final-kurento-3p-10s-t3medium\",\n",
    "    \"loadtest-webrtc-final-kurento-3p-10s-t3medium-2\",\n",
    "    \"loadtest-webrtc-final-kurento-3p-10s-t3medium-wait\",\n",
    "    \"loadtest-webrtc-final-kurento-3p-10s-t3medium-retry\",\n",
    "    \"loadtest-webrtc-final-kurento-3p-20s-t3medium\",\n",
    "    \"loadtest-webrtc-final-kurento-3p-20s-t3medium-2\",\n",
    "    \"loadtest-webrtc-final-kurento-3p-20s-t3medium-wait\",\n",
    "    \"loadtest-webrtc-final-kurento-3p-20s-t3medium-retry\",\n",
    "    \"loadtest-webrtc-final-kurento-3p-40s-t3medium\",\n",
    "    \"loadtest-webrtc-final-kurento-3p-40s-t3medium-2\",\n",
    "    \"loadtest-webrtc-final-kurento-3p-40s-t3medium-wait\",\n",
    "    \"loadtest-webrtc-final-kurento-3p-40s-t3medium-retry\",\n",
    "]\n",
    "\n",
    "index_mediasoup_names = [\n",
    "    \"loadtest-webrtc-final-mediasoup-2p-t3medium\",\n",
    "    \"loadtest-webrtc-final-mediasoup-2p-t3medium-2\",\n",
    "    \"loadtest-webrtc-final-mediasoup-2p-t3medium-wait\",\n",
    "    \"loadtest-webrtc-final-mediasoup-2p-t3medium-retry\",\n",
    "    \"loadtest-webrtc-final-mediasoup-5p-t3medium\",\n",
    "    \"loadtest-webrtc-final-mediasoup-5p-t3medium-2\",\n",
    "    \"loadtest-webrtc-final-mediasoup-5p-t3medium-wait\",\n",
    "    \"loadtest-webrtc-final-mediasoup-5p-t3medium-retry\",\n",
    "    \"loadtest-webrtc-final-mediasoup-8p-t3medium\",\n",
    "    \"loadtest-webrtc-final-mediasoup-8p-t3medium-2\",\n",
    "    \"loadtest-webrtc-final-mediasoup-8p-t3medium-wait\",\n",
    "    \"loadtest-webrtc-final-mediasoup-8p-t3medium-retry\",\n",
    "    \"loadtest-webrtc-final-mediasoup-3p-10s-t3medium\",\n",
    "    \"loadtest-webrtc-final-mediasoup-3p-10s-t3medium-2\",\n",
    "    \"loadtest-webrtc-final-mediasoup-3p-10s-t3medium-wait\",\n",
    "    \"loadtest-webrtc-final-mediasoup-3p-10s-t3medium-retry\",\n",
    "    \"loadtest-webrtc-final-mediasoup-3p-20s-t3medium\",\n",
    "    \"loadtest-webrtc-final-mediasoup-3p-20s-t3medium-2\",\n",
    "    \"loadtest-webrtc-final-mediasoup-3p-20s-t3medium-wait\",\n",
    "    \"loadtest-webrtc-final-mediasoup-3p-20s-t3medium-retry\",\n",
    "    \"loadtest-webrtc-final-mediasoup-3p-40s-t3medium\",\n",
    "    \"loadtest-webrtc-final-mediasoup-3p-40s-t3medium-2\",\n",
    "    \"loadtest-webrtc-final-mediasoup-3p-40s-t3medium-wait\",\n",
    "    \"loadtest-webrtc-final-mediasoup-3p-40s-t3medium-retry\",\n",
    "]\n",
    "\n",
    "index_list_names = index_kurento_names + index_mediasoup_names\n",
    "\n",
    "node_types = [\"browseremulator\", \"masternode\", \"medianode\"]\n",
    "packet_types = [\"inbound\", \"outbound\"]\n",
    "\n",
    "seconds_per_fragment = 17\n",
    "\n",
    "start_end_times = pd.read_json(\"dfs_final/start-end-times.json\", orient=\"index\")\n",
    "start_end_times[\"from\"] = pd.to_datetime(\n",
    "    start_end_times[\"from\"], format=\"ISO8601\"\n",
    ").dt.tz_convert(\"UTC\")\n",
    "start_end_times[\"to\"] = pd.to_datetime(\n",
    "    start_end_times[\"to\"], format=\"ISO8601\"\n",
    ").dt.tz_convert(\"UTC\")\n",
    "\n",
    "\n",
    "def timestamp_to_secs(df_node, index, cpu_times=True):\n",
    "    df_tmp = df_node.copy()\n",
    "    df_tmp[\"@timestamp\"] = pd.to_datetime(df_tmp[\"@timestamp\"], format=\"ISO8601\")\n",
    "    tmp_serie = pd.Series(\n",
    "        [df_tmp[\"@timestamp\"].max(), start_end_times.loc[index, \"to\"]]\n",
    "    )\n",
    "    end_time = tmp_serie.min() if cpu_times else tmp_serie.max()\n",
    "    df_tmp = df_tmp[df_tmp[\"@timestamp\"] < end_time]\n",
    "    tmp_serie = pd.Series(\n",
    "        [df_tmp[\"@timestamp\"].min(), start_end_times.loc[index, \"from\"]]\n",
    "    )\n",
    "    start_time = tmp_serie.max() if cpu_times else tmp_serie.min()\n",
    "    df_tmp[\"timestamp_secs\"] = (df_tmp[\"@timestamp\"] - start_time).dt.total_seconds()\n",
    "    return df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [\n",
    "    pd.read_csv(f\"dfs_final/{x}.csv\")\n",
    "    if os.path.isfile(f\"dfs_final/{x}.csv\")\n",
    "    else pd.DataFrame()\n",
    "    for x in index_list_names\n",
    "]\n",
    "\n",
    "\n",
    "for i, df_user in enumerate(df_list):\n",
    "    if not df_user.empty:\n",
    "        index = index_list_names[i]\n",
    "        start_test_time = start_end_times.loc[index, \"from\"]\n",
    "\n",
    "        df_user[\"@timestamp\"] = pd.to_datetime(df_user[\"@timestamp\"], format=\"ISO8601\")\n",
    "        df_cut_index_0 = df_user[df_user[\"cut_index\"] == 0]\n",
    "        for index, row in df_cut_index_0.iterrows():\n",
    "            start_user_qoe_time = row[\"@timestamp\"]\n",
    "            time_diff = start_user_qoe_time - start_test_time\n",
    "            userFrom = row[\"userFrom\"]\n",
    "            userTo = row[\"userTo\"]\n",
    "            session = row[\"session\"]\n",
    "\n",
    "            df_user.loc[\n",
    "                (df_user[\"userFrom\"] == userFrom)\n",
    "                & (df_user[\"userTo\"] == userTo)\n",
    "                & (df_user[\"session\"] == session),\n",
    "                \"cut_index\",\n",
    "            ] = (\n",
    "                df_user.loc[\n",
    "                    (df_user[\"userFrom\"] == userFrom)\n",
    "                    & (df_user[\"userTo\"] == userTo)\n",
    "                    & (df_user[\"session\"] == session),\n",
    "                    \"cut_index\",\n",
    "                ]\n",
    "                * seconds_per_fragment\n",
    "                + time_diff.seconds\n",
    "            )\n",
    "\n",
    "index_data = []\n",
    "\n",
    "\n",
    "data_types = node_types + packet_types\n",
    "\n",
    "\n",
    "for i, df_user in enumerate(df_list):\n",
    "    index = index_list_names[i]\n",
    "\n",
    "    splitted = index.split(\"-\")\n",
    "\n",
    "    publishers = int(splitted[4][:-1])\n",
    "\n",
    "    subscribers = 0\n",
    "\n",
    "    subscribers_parsed = splitted[5]\n",
    "\n",
    "    if subscribers_parsed[-1] == \"s\":\n",
    "        subscribers = int(subscribers_parsed[:-1])\n",
    "\n",
    "    users = publishers + subscribers\n",
    "\n",
    "    repeat = 1\n",
    "\n",
    "    type = splitted[-1]\n",
    "\n",
    "    if type not in data_types:\n",
    "        if type == \"t3medium\":\n",
    "            repeat = \"1\"\n",
    "\n",
    "        else:\n",
    "            repeat = type\n",
    "\n",
    "        index_data.append(\n",
    "            {\n",
    "                \"type\": repeat,\n",
    "                \"publishers\": publishers,\n",
    "                \"subscribers\": subscribers,\n",
    "                \"users\": users,\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i, df_tmp in enumerate(df_list):\n",
    "    if not df_tmp.empty:\n",
    "        average = df_tmp[\"vmaf\"].mean()\n",
    "        median = df_tmp[\"vmaf\"].median()\n",
    "        min = df_tmp[\"vmaf\"].min()\n",
    "        max = df_tmp[\"vmaf\"].max()\n",
    "        std = df_tmp[\"vmaf\"].std()\n",
    "        data.append([index_list_names[i], average, median, std, min, max])\n",
    "\n",
    "pd.DataFrame(data, columns=[\"index_type\", \"average\", \"median\", \"std\", \"min\", \"max\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INDIVIDUAL PLOTS PARAMETERS\n",
    "\n",
    "# Index of index_list to use\n",
    "index = 45\n",
    "# If there is only one metric in display, choose which one\n",
    "metric = \"vmaf\"\n",
    "\n",
    "show_full_range = True\n",
    "\n",
    "# Calculations\n",
    "index_name = index_list_names[index]\n",
    "metric_label = metric.upper()\n",
    "qoe_metrics_normalized = [\"vmaf\", \"msssim\", \"ssim\", \"vifp\", \"pesq\", \"visqol\"]\n",
    "qoe_metrics_not_normalized = [\"psnr\", \"psnrhvs\", \"psnrhvsm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [25, 10]\n",
    "colors = [\"blue\", \"orange\", \"green\", \"red\"]\n",
    "k = 0\n",
    "\n",
    "for metric in qoe_metrics_normalized:\n",
    "    for i, df_tmp in enumerate(df_list):\n",
    "        if not df_tmp.empty:\n",
    "            if k == 0:\n",
    "                fig, ax = plt.subplots()\n",
    "            df_mean = df_tmp.groupby([\"cut_index\"]).mean(numeric_only=True)\n",
    "            plot_name = index_list_names[i]\n",
    "            if not df_mean.empty:\n",
    "                ax.plot(df_mean.index, df_mean[metric], label=plot_name)\n",
    "                ax.axvline(\n",
    "                    x=df_mean.index.max(),\n",
    "                    linestyle=\"--\",\n",
    "                    alpha=0.7,\n",
    "                )\n",
    "                ax.axvline(\n",
    "                    x=df_mean.index.min(),\n",
    "                    linestyle=\"--\",\n",
    "                    alpha=0.7,\n",
    "                )\n",
    "\n",
    "            if k == 3:\n",
    "                ax.set_xlabel(\"timestamp (seconds)\")\n",
    "                ax.set_ylabel(metric)\n",
    "                ax.grid()\n",
    "                ax.set_ylim(-0.5, 1.05)\n",
    "                ax.set_yticks(np.arange(-0.5, 1.05, 0.05))\n",
    "                fig.legend(loc=\"lower left\")\n",
    "                fig.suptitle(f\"{metric} over time (mean, {plot_name})\")\n",
    "                fig.savefig(f\"images_final/{plot_name}_{metric}.png\")\n",
    "            k = (k + 1) % 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [25, 10]\n",
    "typologies = [\"2p\", \"5p\", \"8p\", \"3p-10s\", \"3p-20s\", \"3p-40s\"]\n",
    "media_nodes = [\"kurento\", \"mediasoup\"]\n",
    "colors = [\"blue\", \"orange\", \"green\", \"red\"]\n",
    "for typology in typologies:\n",
    "    for media_node in media_nodes:\n",
    "        fig, ax = plt.subplots()\n",
    "        target_names = filter(\n",
    "            lambda x: typology in x and media_node in x, index_list_names\n",
    "        )\n",
    "\n",
    "        max_x = -1\n",
    "        for i, target_name in enumerate(target_names):\n",
    "            df_node = pd.read_csv(f\"dfs_final/{target_name}-medianode.csv\")\n",
    "            # remove entries with cpu < 0.001\n",
    "            # df_node = df_node[df_node[\"cpu\"] > 0.001]\n",
    "            df_node = timestamp_to_secs(df_node, target_name)\n",
    "            df_node = df_node.drop(columns=[\"@timestamp\", \"memory\"]).dropna()\n",
    "            ax.plot(\n",
    "                df_node[\"timestamp_secs\"],\n",
    "                df_node[\"cpu\"],\n",
    "                color=colors[i],\n",
    "                label=target_name,\n",
    "            )\n",
    "            plt.axvline(\n",
    "                x=df_node[\"timestamp_secs\"].max(),\n",
    "                color=colors[i],\n",
    "                linestyle=\"--\",\n",
    "                alpha=0.7,\n",
    "                label=\"End of test \" + target_name,\n",
    "            )\n",
    "            max_x = np.max(np.array([max_x, df_node[\"timestamp_secs\"].max()]))\n",
    "\n",
    "        ax.set_xlabel(\"timestamp (seconds)\")\n",
    "        ax.set_ylabel(\"CPU usage (%)\")\n",
    "        ax.grid()\n",
    "        ax.set_ylim(0, 1.05)\n",
    "        ax.set_yticks(np.arange(0, 1.05, 0.05))\n",
    "        # ax.set_xticks(np.arange(0, max_x, 120))\n",
    "\n",
    "        fig.suptitle(f\"CPU usage over time ({typology}, {media_node})\")\n",
    "        fig.legend(loc=\"right\")\n",
    "        fig.savefig(f\"images_final/{typology}_{media_node}_cpu.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [25, 10]\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "webrtc_stats_y = ax.twinx()\n",
    "\n",
    "aggregation_map = {\"@timestamp\": \"first\"}\n",
    "for metric in qoe_metrics_normalized:\n",
    "    aggregation_map[metric] = \"mean\"\n",
    "\n",
    "df_tmp = df_list[index].groupby(\"cut_index\").agg(aggregation_map)\n",
    "df_tmp = timestamp_to_secs(df_tmp, index_name)\n",
    "df_node = pd.read_csv(f\"dfs_final/{index_name}-medianode.csv\")\n",
    "df_node = timestamp_to_secs(df_node, index_name)\n",
    "df = df_tmp\n",
    "\n",
    "df_node_cpu = df_node.drop(columns=[\"memory\"]).dropna()\n",
    "df_node_memory = df_node.drop(columns=[\"cpu\"]).dropna()\n",
    "\n",
    "df_stats_inbound = pd.read_csv(f\"dfs_final/{index_name}-webrtc-stats-inbound.csv\")\n",
    "df_stats_outbound = pd.read_csv(f\"dfs_final/{index_name}-webrtc-stats-outbound.csv\")\n",
    "df_stats_inbound[\"@timestamp\"] = pd.to_datetime(\n",
    "    df_stats_inbound[\"@timestamp\"], format=\"ISO8601\"\n",
    ")\n",
    "df_stats_outbound[\"@timestamp\"] = pd.to_datetime(\n",
    "    df_stats_outbound[\"@timestamp\"], format=\"ISO8601\"\n",
    ")\n",
    "df_stats_inbound = df_stats_inbound.drop(columns=\"user_id\")\n",
    "df_stats_outbound = df_stats_outbound.drop(columns=\"user_id\")\n",
    "df_stats_inbound = df_stats_inbound.groupby(\"@timestamp\").mean()\n",
    "df_stats_outbound = df_stats_outbound.groupby(\"@timestamp\").mean()\n",
    "\n",
    "df_stats_inbound = timestamp_to_secs(df_stats_inbound, index_name)\n",
    "df_stats_outbound = timestamp_to_secs(df_stats_outbound, index_name)\n",
    "\n",
    "qoe_zorder = 10\n",
    "resource_zorder = 0\n",
    "\n",
    "qoe_linewidth = 3\n",
    "resource_linewidth = 1\n",
    "\n",
    "legend_handles = []\n",
    "for metric in qoe_metrics_normalized:\n",
    "    legend_handles.append(\n",
    "        ax.plot(\n",
    "            df[\"@timestamp\"],\n",
    "            df[metric],\n",
    "            label=metric,\n",
    "            marker=\"o\",\n",
    "            zorder=qoe_zorder,\n",
    "            lw=qoe_linewidth,\n",
    "        )\n",
    "    )\n",
    "legend_handles.append(\n",
    "    ax.plot(\n",
    "        df_node_cpu[\"@timestamp\"],\n",
    "        df_node_cpu[\"cpu\"],\n",
    "        \"g\",\n",
    "        label=\"cpu\",\n",
    "        zorder=resource_zorder,\n",
    "        lw=resource_linewidth,\n",
    "        linestyle=\"--\",\n",
    "    )\n",
    ")\n",
    "legend_handles.append(\n",
    "    ax.plot(\n",
    "        df_node_memory[\"@timestamp\"],\n",
    "        df_node_memory[\"memory\"],\n",
    "        \"c\",\n",
    "        label=\"memory\",\n",
    "        zorder=resource_zorder,\n",
    "        lw=resource_linewidth,\n",
    "        linestyle=\"--\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "for column in df_stats_inbound.columns[1:]:\n",
    "    # Maybe readd gpSum?\n",
    "    if (\n",
    "        not \"bytesSent\" in column\n",
    "        and not \"packetsSent\" in column\n",
    "        and not \"qpSum\" in column\n",
    "        and not \"framesEncoded\" in column\n",
    "    ):\n",
    "        legend_handles.append(\n",
    "            webrtc_stats_y.plot(\n",
    "                df_stats_inbound.index, df_stats_inbound[column], label=column\n",
    "            )\n",
    "        )\n",
    "\n",
    "ax.set_title(f\"QOE metric (normalized) over time (mean, worker data, {index_name})\")\n",
    "ax.set_xlabel(\"timestamp (day hour:minute)\")\n",
    "ax.set_ylabel(\"QOE metric (normalized), CPU %, Memory %\")\n",
    "webrtc_stats_y.set_ylabel(\"WebRTC stats\")\n",
    "ax.grid()\n",
    "ax.legend(loc=\"upper left\")\n",
    "webrtc_stats_y.legend(loc=\"center left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = qoe_metrics_normalized + qoe_metrics_not_normalized\n",
    "\n",
    "def ols(dir, x_label, df):\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "    X = df[x_label]\n",
    "\n",
    "\n",
    "    X = sm.add_constant(X)  # adding a constant\n",
    "    for metric in metrics:\n",
    "        Y = df[metric]\n",
    "\n",
    "        model = sm.OLS(Y, X).fit()\n",
    "        summary = model.summary()\n",
    "\n",
    "        with open(f\"{dir}/{metric}-summary.tex\", \"w\") as fh:\n",
    "            fh.write(summary.as_latex())\n",
    "\n",
    "        with open(f\"{dir}/{metric}-summary.html\", \"w\") as fh:\n",
    "            fh.write(summary.as_html())\n",
    "\n",
    "        with open(f\"{dir}/{metric}.txt\", \"w\") as fh:\n",
    "            fh.write(summary.as_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = pd.concat(df_list, ignore_index=True)\n",
    "ols(\"results_ols/results_all\", \"user_count\", df_tmp)\n",
    "\n",
    "df_tmp = pd.concat(df_list[:24], ignore_index=True)\n",
    "ols(\"results_ols/results_kurento\", \"user_count\", df_tmp)\n",
    "\n",
    "df_tmp = pd.concat(df_list[24:], ignore_index=True)\n",
    "ols(\"results_ols/results_mediasoup\", \"user_count\", df_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.47 GiB for an array with shape (10, 33188642) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32me:\\GitHub\\Performance-evaluation-WebRTC-analysis\\final.ipynb Cell 12\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/GitHub/Performance-evaluation-WebRTC-analysis/final.ipynb#X14sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m df_webrtc_outbound \u001b[39m=\u001b[39m timestamp_to_secs(df_webrtc_outbound, index_name, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/GitHub/Performance-evaluation-WebRTC-analysis/final.ipynb#X14sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m df_webrtc_outbound[\u001b[39m\"\u001b[39m\u001b[39mtimestamp_secs\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df_webrtc_outbound[\u001b[39m\"\u001b[39m\u001b[39mtimestamp_secs\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mround(\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/GitHub/Performance-evaluation-WebRTC-analysis/final.ipynb#X14sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/GitHub/Performance-evaluation-WebRTC-analysis/final.ipynb#X14sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/GitHub/Performance-evaluation-WebRTC-analysis/final.ipynb#X14sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m merged_outbound_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mmerge(\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/GitHub/Performance-evaluation-WebRTC-analysis/final.ipynb#X14sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     df_tmp, df_webrtc_outbound, on\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtimestamp_secs\u001b[39;49m\u001b[39m\"\u001b[39;49m, how\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39minner\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/GitHub/Performance-evaluation-WebRTC-analysis/final.ipynb#X14sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/GitHub/Performance-evaluation-WebRTC-analysis/final.ipynb#X14sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m df_webrtc_outbound_merged_list\u001b[39m.\u001b[39mappend(merged_outbound_df)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:183\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    169\u001b[0m     op \u001b[39m=\u001b[39m _MergeOperation(\n\u001b[0;32m    170\u001b[0m         left_df,\n\u001b[0;32m    171\u001b[0m         right_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    181\u001b[0m         validate\u001b[39m=\u001b[39mvalidate,\n\u001b[0;32m    182\u001b[0m     )\n\u001b[1;32m--> 183\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result(copy\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:885\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    881\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indicator_pre_merge(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright)\n\u001b[0;32m    883\u001b[0m join_index, left_indexer, right_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_join_info()\n\u001b[1;32m--> 885\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reindex_and_concat(\n\u001b[0;32m    886\u001b[0m     join_index, left_indexer, right_indexer, copy\u001b[39m=\u001b[39;49mcopy\n\u001b[0;32m    887\u001b[0m )\n\u001b[0;32m    888\u001b[0m result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_type)\n\u001b[0;32m    890\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindicator:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:876\u001b[0m, in \u001b[0;36m_MergeOperation._reindex_and_concat\u001b[1;34m(self, join_index, left_indexer, right_indexer, copy)\u001b[0m\n\u001b[0;32m    874\u001b[0m left\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m llabels\n\u001b[0;32m    875\u001b[0m right\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m rlabels\n\u001b[1;32m--> 876\u001b[0m result \u001b[39m=\u001b[39m concat([left, right], axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m    877\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:393\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    378\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    380\u001b[0m op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[0;32m    381\u001b[0m     objs,\n\u001b[0;32m    382\u001b[0m     axis\u001b[39m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m     sort\u001b[39m=\u001b[39msort,\n\u001b[0;32m    391\u001b[0m )\n\u001b[1;32m--> 393\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result()\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:680\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m             indexers[ax] \u001b[39m=\u001b[39m obj_labels\u001b[39m.\u001b[39mget_indexer(new_labels)\n\u001b[0;32m    678\u001b[0m     mgrs_indexers\u001b[39m.\u001b[39mappend((obj\u001b[39m.\u001b[39m_mgr, indexers))\n\u001b[1;32m--> 680\u001b[0m new_data \u001b[39m=\u001b[39m concatenate_managers(\n\u001b[0;32m    681\u001b[0m     mgrs_indexers, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnew_axes, concat_axis\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbm_axis, copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy\n\u001b[0;32m    682\u001b[0m )\n\u001b[0;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    684\u001b[0m     new_data\u001b[39m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\concat.py:131\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[39m# Assertions disabled for performance\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[39m# for tup in mgrs_indexers:\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[39m#    # caller is responsible for ensuring this\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[39m#    indexers = tup[1]\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[39m#    assert concat_axis not in indexers\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[39mif\u001b[39;00m concat_axis \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 131\u001b[0m     mgrs \u001b[39m=\u001b[39m _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)\n\u001b[0;32m    132\u001b[0m     \u001b[39mreturn\u001b[39;00m mgrs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mconcat_horizontal(mgrs, axes)\n\u001b[0;32m    134\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mgrs_indexers) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m mgrs_indexers[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mnblocks \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\concat.py:230\u001b[0m, in \u001b[0;36m_maybe_reindex_columns_na_proxy\u001b[1;34m(axes, mgrs_indexers, needs_copy)\u001b[0m\n\u001b[0;32m    220\u001b[0m         mgr \u001b[39m=\u001b[39m mgr\u001b[39m.\u001b[39mreindex_indexer(\n\u001b[0;32m    221\u001b[0m             axes[i],\n\u001b[0;32m    222\u001b[0m             indexers[i],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    227\u001b[0m             use_na_proxy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,  \u001b[39m# only relevant for i==0\u001b[39;00m\n\u001b[0;32m    228\u001b[0m         )\n\u001b[0;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m needs_copy \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m indexers:\n\u001b[1;32m--> 230\u001b[0m         mgr \u001b[39m=\u001b[39m mgr\u001b[39m.\u001b[39;49mcopy()\n\u001b[0;32m    232\u001b[0m     new_mgrs\u001b[39m.\u001b[39mappend(mgr)\n\u001b[0;32m    233\u001b[0m \u001b[39mreturn\u001b[39;00m new_mgrs\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:587\u001b[0m, in \u001b[0;36mBaseBlockManager.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    584\u001b[0m         res\u001b[39m.\u001b[39m_blklocs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_blklocs\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m    586\u001b[0m \u001b[39mif\u001b[39;00m deep:\n\u001b[1;32m--> 587\u001b[0m     res\u001b[39m.\u001b[39;49m_consolidate_inplace()\n\u001b[0;32m    588\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1750\u001b[0m, in \u001b[0;36mBlockManager._consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1744\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_consolidate_inplace\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[39m# In general, _consolidate_inplace should only be called via\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m     \u001b[39m#  DataFrame._consolidate_inplace, otherwise we will fail to invalidate\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m     \u001b[39m#  the DataFrame's _item_cache. The exception is for newly-created\u001b[39;00m\n\u001b[0;32m   1748\u001b[0m     \u001b[39m#  BlockManager objects not yet attached to a DataFrame.\u001b[39;00m\n\u001b[0;32m   1749\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_consolidated():\n\u001b[1;32m-> 1750\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks \u001b[39m=\u001b[39m _consolidate(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblocks)\n\u001b[0;32m   1751\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_consolidated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1752\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_known_consolidated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2217\u001b[0m, in \u001b[0;36m_consolidate\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m   2215\u001b[0m new_blocks: \u001b[39mlist\u001b[39m[Block] \u001b[39m=\u001b[39m []\n\u001b[0;32m   2216\u001b[0m \u001b[39mfor\u001b[39;00m (_can_consolidate, dtype), group_blocks \u001b[39min\u001b[39;00m grouper:\n\u001b[1;32m-> 2217\u001b[0m     merged_blocks, _ \u001b[39m=\u001b[39m _merge_blocks(\n\u001b[0;32m   2218\u001b[0m         \u001b[39mlist\u001b[39;49m(group_blocks), dtype\u001b[39m=\u001b[39;49mdtype, can_consolidate\u001b[39m=\u001b[39;49m_can_consolidate\n\u001b[0;32m   2219\u001b[0m     )\n\u001b[0;32m   2220\u001b[0m     new_blocks \u001b[39m=\u001b[39m extend_blocks(merged_blocks, new_blocks)\n\u001b[0;32m   2221\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(new_blocks)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2242\u001b[0m, in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[0;32m   2235\u001b[0m new_values: ArrayLike\n\u001b[0;32m   2237\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(blocks[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39mdtype):\n\u001b[0;32m   2238\u001b[0m     \u001b[39m# error: List comprehension has incompatible type List[Union[ndarray,\u001b[39;00m\n\u001b[0;32m   2239\u001b[0m     \u001b[39m# ExtensionArray]]; expected List[Union[complex, generic,\u001b[39;00m\n\u001b[0;32m   2240\u001b[0m     \u001b[39m# Sequence[Union[int, float, complex, str, bytes, generic]],\u001b[39;00m\n\u001b[0;32m   2241\u001b[0m     \u001b[39m# Sequence[Sequence[Any]], SupportsArray]]\u001b[39;00m\n\u001b[1;32m-> 2242\u001b[0m     new_values \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mvstack([b\u001b[39m.\u001b[39;49mvalues \u001b[39mfor\u001b[39;49;00m b \u001b[39min\u001b[39;49;00m blocks])  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   2243\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2244\u001b[0m     bvals \u001b[39m=\u001b[39m [blk\u001b[39m.\u001b[39mvalues \u001b[39mfor\u001b[39;00m blk \u001b[39min\u001b[39;00m blocks]\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\numpy\\core\\shape_base.py:289\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(tup, dtype, casting)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(arrs, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    288\u001b[0m     arrs \u001b[39m=\u001b[39m [arrs]\n\u001b[1;32m--> 289\u001b[0m \u001b[39mreturn\u001b[39;00m _nx\u001b[39m.\u001b[39;49mconcatenate(arrs, \u001b[39m0\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mdtype, casting\u001b[39m=\u001b[39;49mcasting)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.47 GiB for an array with shape (10, 33188642) and data type float64"
     ]
    }
   ],
   "source": [
    "df_merged_list = []\n",
    "\n",
    "df_webrtc_inbound_merged_list = []\n",
    "df_webrtc_outbound_merged_list = []\n",
    "\n",
    "for i, df_tmp in enumerate(df_list):\n",
    "\n",
    "    index_name = index_list_names[i]\n",
    "\n",
    "    df_node = pd.read_csv(f\"dfs_final/{index_name}-medianode.csv\")\n",
    "\n",
    "    df_node = df_node.drop(columns=[\"memory\"]).dropna()\n",
    "\n",
    "    df_tmp = timestamp_to_secs(df_tmp, index_name, False)\n",
    "\n",
    "    df_node = timestamp_to_secs(df_node, index_name, False)\n",
    "\n",
    "    df_tmp[\"timestamp_secs\"] = df_tmp[\"timestamp_secs\"].round(-1)\n",
    "\n",
    "    df_node[\"timestamp_secs\"] = df_node[\"timestamp_secs\"].round(-1)\n",
    "\n",
    "    # df_tmp = df_tmp.groupby([\"timestamp_secs\"]).mean(numeric_only=True)\n",
    "\n",
    "\n",
    "    merged_df = pd.merge(df_tmp, df_node, on=\"timestamp_secs\", how=\"inner\")\n",
    "\n",
    "\n",
    "    df_merged_list.append(merged_df)\n",
    "\n",
    "    df_webrtc_inbound = pd.read_csv(f\"dfs_final/{index_name}-webrtc-stats-inbound.csv\")\n",
    "\n",
    "    df_webrtc_inbound = timestamp_to_secs(df_webrtc_inbound, index_name, False)\n",
    "    df_webrtc_inbound[\"timestamp_secs\"] = df_webrtc_inbound[\"timestamp_secs\"].round(-1)\n",
    "\n",
    "    merged_inbound_df = pd.merge(\n",
    "        df_tmp, df_webrtc_inbound, on=\"timestamp_secs\", how=\"inner\"\n",
    "    )\n",
    "\n",
    "    df_webrtc_inbound_merged_list.append(merged_inbound_df)\n",
    "\n",
    "    df_webrtc_outbound = pd.read_csv(\n",
    "        f\"dfs_final/{index_name}-webrtc-stats-outbound.csv\"\n",
    "    )\n",
    "\n",
    "    df_webrtc_outbound = timestamp_to_secs(df_webrtc_outbound, index_name, False)\n",
    "    df_webrtc_outbound[\"timestamp_secs\"] = df_webrtc_outbound[\"timestamp_secs\"].round(\n",
    "        -1\n",
    "    )\n",
    "\n",
    "    merged_outbound_df = pd.merge(\n",
    "        df_tmp, df_webrtc_outbound, on=\"timestamp_secs\", how=\"inner\"\n",
    "    )\n",
    "\n",
    "    df_webrtc_outbound_merged_list.append(merged_outbound_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = pd.concat(df_merged_list, ignore_index=True)\n",
    "ols(\"results_ols/results_all_cpu\", \"cpu\", df_tmp)\n",
    "\n",
    "df_tmp = pd.concat(df_merged_list[:24], ignore_index=True)\n",
    "ols(\"results_ols/results_kurento_cpu\", \"cpu\", df_tmp)\n",
    "\n",
    "df_tmp = pd.concat(df_merged_list[24:], ignore_index=True)\n",
    "ols(\"results_ols/results_mediasoup_cpu\", \"cpu\", df_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = pd.concat(\n",
    "    [\n",
    "        df_list[0],\n",
    "        df_list[1],\n",
    "        df_list[4],\n",
    "        df_list[5],\n",
    "        df_list[8],\n",
    "        df_list[9],\n",
    "        df_list[12],\n",
    "        df_list[13],\n",
    "        df_list[16],\n",
    "        df_list[17],\n",
    "        df_list[20],\n",
    "        df_list[21],\n",
    "        df_list[24],\n",
    "        df_list[25],\n",
    "        df_list[28],\n",
    "        df_list[29],\n",
    "        df_list[32],\n",
    "        df_list[33],\n",
    "        df_list[36],\n",
    "        df_list[37],\n",
    "        df_list[40],\n",
    "        df_list[41],\n",
    "        df_list[44],\n",
    "        df_list[45],\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "ols(\"results_ols/results_default_all\", \"user_count\", df_tmp)\n",
    "\n",
    "df_tmp = pd.concat(\n",
    "    [\n",
    "        df_list[2],\n",
    "        df_list[6],\n",
    "        df_list[10],\n",
    "        df_list[14],\n",
    "        df_list[18],\n",
    "        df_list[22],\n",
    "        df_list[26],\n",
    "        df_list[30],\n",
    "        df_list[34],\n",
    "        df_list[38],\n",
    "        df_list[42],\n",
    "        df_list[46],\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "ols(\"results_ols/results_wait_all\", \"user_count\", df_tmp)\n",
    "\n",
    "df_tmp = pd.concat(\n",
    "    [\n",
    "        df_list[3],\n",
    "        df_list[7],\n",
    "        df_list[11],\n",
    "        df_list[15],\n",
    "        df_list[19],\n",
    "        df_list[23],\n",
    "        df_list[27],\n",
    "        df_list[31],\n",
    "        df_list[35],\n",
    "        df_list[39],\n",
    "        df_list[43],\n",
    "        df_list[47],\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "ols(\"results_ols/results_retry_all\", \"user_count\", df_tmp)\n",
    "\n",
    "df_tmp = pd.concat(\n",
    "    [    \n",
    "        df_list[0],\n",
    "        df_list[1],\n",
    "        df_list[4],\n",
    "        df_list[5],\n",
    "        df_list[8],\n",
    "        df_list[9],\n",
    "        df_list[12],\n",
    "        df_list[13],\n",
    "        df_list[16],\n",
    "        df_list[17],\n",
    "        df_list[20],\n",
    "        df_list[21],\n",
    "        df_list[24]\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "ols(\"results_ols/results_default_kurento\", \"user_count\", df_tmp)\n",
    "\n",
    "df_tmp = pd.concat(\n",
    "    [\n",
    "        df_list[2],\n",
    "        df_list[6],\n",
    "        df_list[10],\n",
    "        df_list[14],\n",
    "        df_list[18],\n",
    "        df_list[22],\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "ols(\"results_ols/results_wait_kurento\", \"user_count\", df_tmp)\n",
    "\n",
    "df_tmp = pd.concat(\n",
    "    [\n",
    "        df_list[3],\n",
    "        df_list[7],\n",
    "        df_list[11],\n",
    "        df_list[15],\n",
    "        df_list[19],\n",
    "        df_list[23],\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "ols(\"results_ols/results_retry_kurento\", \"user_count\", df_tmp)\n",
    "\n",
    "df_tmp = pd.concat(\n",
    "    [\n",
    "        df_list[24],\n",
    "        df_list[25],\n",
    "        df_list[28],\n",
    "        df_list[29],\n",
    "        df_list[32],\n",
    "        df_list[33],\n",
    "        df_list[36],\n",
    "        df_list[37],\n",
    "        df_list[40],\n",
    "        df_list[41],\n",
    "        df_list[44],\n",
    "        df_list[45],\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "ols(\"results_ols/results_default_mediasoup\", \"user_count\", df_tmp)\n",
    "\n",
    "df_tmp = pd.concat(\n",
    "    [\n",
    "        df_list[26],\n",
    "        df_list[30],\n",
    "        df_list[34],\n",
    "        df_list[38],\n",
    "        df_list[42],\n",
    "        df_list[46],\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "ols(\"results_ols/results_wait_mediasoup\", \"user_count\", df_tmp)\n",
    "\n",
    "df_tmp = pd.concat(\n",
    "    [\n",
    "        df_list[27],\n",
    "        df_list[31],\n",
    "        df_list[35],\n",
    "        df_list[39],\n",
    "        df_list[43],\n",
    "        df_list[47],\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "ols(\"results_ols/results_retry_mediasoup\", \"user_count\", df_tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = pd.concat(\n",
    "    [\n",
    "        df_merged_list[0],\n",
    "        df_merged_list[1],\n",
    "        df_merged_list[4],\n",
    "        df_merged_list[5],\n",
    "        df_merged_list[8],\n",
    "        df_merged_list[9],\n",
    "        df_merged_list[12],\n",
    "        df_merged_list[13],\n",
    "        df_merged_list[16],\n",
    "        df_merged_list[17],\n",
    "        df_merged_list[20],\n",
    "        df_merged_list[21],\n",
    "        df_merged_list[24],\n",
    "        df_merged_list[25],\n",
    "        df_merged_list[28],\n",
    "        df_merged_list[29],\n",
    "        df_merged_list[32],\n",
    "        df_merged_list[33],\n",
    "        df_merged_list[36],\n",
    "        df_merged_list[37],\n",
    "        df_merged_list[40],\n",
    "        df_merged_list[41],\n",
    "        df_merged_list[44],\n",
    "        df_merged_list[45],\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "ols(\"results_ols/results_default_all_cpu\", \"cpu\", df_tmp)\n",
    "\n",
    "df_tmp = pd.concat(\n",
    "    [\n",
    "        df_merged_list[2],\n",
    "        df_merged_list[6],\n",
    "        df_merged_list[10],\n",
    "        df_merged_list[14],\n",
    "        df_merged_list[18],\n",
    "        df_merged_list[22],\n",
    "        df_merged_list[26],\n",
    "        df_merged_list[30],\n",
    "        df_merged_list[34],\n",
    "        df_merged_list[38],\n",
    "        df_merged_list[42],\n",
    "        df_merged_list[46],\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "ols(\"results_ols/results_wait_all_cpu\", \"cpu\", df_tmp)\n",
    "\n",
    "df_tmp = pd.concat(\n",
    "    [\n",
    "        df_merged_list[3],\n",
    "        df_merged_list[7],\n",
    "        df_merged_list[11],\n",
    "        df_merged_list[15],\n",
    "        df_merged_list[19],\n",
    "        df_merged_list[23],\n",
    "        df_merged_list[27],\n",
    "        df_merged_list[31],\n",
    "        df_merged_list[35],\n",
    "        df_merged_list[39],\n",
    "        df_merged_list[43],\n",
    "        df_merged_list[47],\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "ols(\"results_ols/results_retry_all_cpu\", \"cpu\", df_tmp)\n",
    "\n",
    "df_tmp = pd.concat(\n",
    "    [    \n",
    "        df_merged_list[0],\n",
    "        df_merged_list[1],\n",
    "        df_merged_list[4],\n",
    "        df_merged_list[5],\n",
    "        df_merged_list[8],\n",
    "        df_merged_list[9],\n",
    "        df_merged_list[12],\n",
    "        df_merged_list[13],\n",
    "        df_merged_list[16],\n",
    "        df_merged_list[17],\n",
    "        df_merged_list[20],\n",
    "        df_merged_list[21],\n",
    "        df_merged_list[24]\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "ols(\"results_ols/results_default_kurento_cpu\", \"cpu\", df_tmp)\n",
    "\n",
    "df_tmp = pd.concat(\n",
    "    [\n",
    "        df_merged_list[2],\n",
    "        df_merged_list[6],\n",
    "        df_merged_list[10],\n",
    "        df_merged_list[14],\n",
    "        df_merged_list[18],\n",
    "        df_merged_list[22],\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "ols(\"results_ols/results_wait_kurento_cpu\", \"cpu\", df_tmp)\n",
    "\n",
    "df_tmp = pd.concat(\n",
    "    [\n",
    "        df_merged_list[3],\n",
    "        df_merged_list[7],\n",
    "        df_merged_list[11],\n",
    "        df_merged_list[15],\n",
    "        df_merged_list[19],\n",
    "        df_merged_list[23],\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "ols(\"results_ols/results_retry_kurento_cpu\", \"cpu\", df_tmp)\n",
    "\n",
    "df_tmp = pd.concat(\n",
    "    [\n",
    "        df_merged_list[24],\n",
    "        df_merged_list[25],\n",
    "        df_merged_list[28],\n",
    "        df_merged_list[29],\n",
    "        df_merged_list[32],\n",
    "        df_merged_list[33],\n",
    "        df_merged_list[36],\n",
    "        df_merged_list[37],\n",
    "        df_merged_list[40],\n",
    "        df_merged_list[41],\n",
    "        df_merged_list[44],\n",
    "        df_merged_list[45],\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "ols(\"results_ols/results_default_mediasoup_cpu\", \"cpu\", df_tmp)\n",
    "\n",
    "df_tmp = pd.concat(\n",
    "    [\n",
    "        df_merged_list[26],\n",
    "        df_merged_list[30],\n",
    "        df_merged_list[34],\n",
    "        df_merged_list[38],\n",
    "        df_merged_list[42],\n",
    "        df_merged_list[46],\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "ols(\"results_ols/results_wait_mediasoup_cpu\", \"cpu\", df_tmp)\n",
    "\n",
    "df_tmp = pd.concat(\n",
    "    [\n",
    "        df_merged_list[27],\n",
    "        df_merged_list[31],\n",
    "        df_merged_list[35],\n",
    "        df_merged_list[39],\n",
    "        df_merged_list[43],\n",
    "        df_merged_list[47],\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "ols(\"results_ols/results_retry_mediasoup_cpu\", \"cpu\", df_tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, df_tmp in enumerate(df_list):\n",
    "    index_name = index_list_names[i]\n",
    "    try:\n",
    "        ols(f\"results_ols/indexes/{index_name}\", \"user_count\", df_tmp)\n",
    "    except:\n",
    "        print(f\"Failed for {index_name}\")\n",
    "\n",
    "for i, df_tmp in enumerate(df_merged_list):\n",
    "    index_name = index_list_names[i]\n",
    "    try:\n",
    "        ols(f\"results_ols/indexes_cpu/{index_name}\", \"cpu\", df_tmp)\n",
    "    except:\n",
    "        print(f\"Failed (cpu) for {index_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "dir = \"test/\"\n",
    "\n",
    "os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "#df = pd.concat(df_merged_list, ignore_index=True)\n",
    "\n",
    "i = 24\n",
    "df = df_merged_list[i]\n",
    "\n",
    "df = df[df[\"cpu\"] < 0.95]\n",
    "\n",
    "X = df[\"user_count\"]\n",
    "\n",
    "metric = \"cpu\"\n",
    "\n",
    "X = sm.add_constant(X)  # adding a constant\n",
    "Y = df[metric]\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    "summary = model.summary()\n",
    "\n",
    "# with open(f\"{dir}/{metric}-summary.tex\", \"w\") as fh:\n",
    "#     fh.write(summary.as_latex())\n",
    "\n",
    "# with open(f\"{dir}/{metric}-summary.html\", \"w\") as fh:\n",
    "#     fh.write(summary.as_html())\n",
    "\n",
    "# with open(f\"{dir}/{metric}.txt\", \"w\") as fh:\n",
    "#     fh.write(summary.as_text())\n",
    "print(index_list_names[i])\n",
    "display(pd.read_html(StringIO(summary.tables[1].as_html()), header=0, index_col=0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loadtest-webrtc-final-kurento-2p-t3medium\n",
      "loadtest-webrtc-final-kurento-2p-t3medium-2\n",
      "loadtest-webrtc-final-kurento-2p-t3medium-wait\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\millenium\\AppData\\Local\\Temp\\ipykernel_6732\\2284071438.py:14: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loadtest-webrtc-final-kurento-2p-t3medium-retry\n",
      "loadtest-webrtc-final-kurento-5p-t3medium\n",
      "loadtest-webrtc-final-kurento-5p-t3medium-2\n",
      "loadtest-webrtc-final-kurento-5p-t3medium-wait\n",
      "loadtest-webrtc-final-kurento-5p-t3medium-retry\n",
      "loadtest-webrtc-final-kurento-8p-t3medium\n",
      "loadtest-webrtc-final-kurento-8p-t3medium-2\n",
      "loadtest-webrtc-final-kurento-8p-t3medium-wait\n",
      "loadtest-webrtc-final-kurento-8p-t3medium-retry\n",
      "loadtest-webrtc-final-kurento-3p-10s-t3medium\n",
      "loadtest-webrtc-final-kurento-3p-10s-t3medium-2\n",
      "loadtest-webrtc-final-kurento-3p-10s-t3medium-wait\n",
      "loadtest-webrtc-final-kurento-3p-10s-t3medium-retry\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,48):\n",
    "    index_name = index_list_names[i]\n",
    "    print(index_name)\n",
    "    df = df_list[i]\n",
    "    os.makedirs(f\"images_final/sns/{index_name}\", exist_ok=True)\n",
    "    #df_merged = df_merged_list[i]\n",
    "\n",
    "\n",
    "    # plot x cpu y vmaf \n",
    "    # fig, ax = plt.subplots()\n",
    "    # sns.lineplot(data=df_merged, x=\"cpu\", y=\"vmaf\", ax=ax)\n",
    "    df = df.sort_values(by=[\"user_count\"])\n",
    "    for metric in metrics:\n",
    "        fig, ax = plt.subplots()\n",
    "        if metric in qoe_metrics_normalized:\n",
    "            ax.set_ylim(0, 1.05)\n",
    "        ax.set_xlim(0, df[\"user_count\"].max() + 1)\n",
    "        ax.set_yticks(np.arange(0, 1.05, 0.1))\n",
    "        sns.lineplot(data=df, x=\"user_count\", y=metric, ax=ax)\n",
    "        plt.grid()\n",
    "        plt.savefig(f\"images_final/sns/{index_name}/{metric}.png\")\n",
    "\n",
    "\n",
    "# algo = Pelt(model=\"rbf\").fit(df[\"vmaf\"].values)\n",
    "# result = algo.predict(pen=10)\n",
    "# for breakpoint_idx in result:\n",
    "#     breakpoint_value = df[\"user_count\"].iloc[breakpoint_idx]\n",
    "#     ax.scatter(breakpoint_value, df[\"vmaf\"].iloc[breakpoint_idx], color='red', marker='o', s=100)\n",
    "\n",
    "# #vertical line\n",
    "\n",
    "# ax.axvline(x=result[0], linestyle=\"--\", alpha=0.7, label=\"Change point\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,48):\n",
    "    print(index_list_names[i])\n",
    "    # TODO: paint the webrtc stats results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

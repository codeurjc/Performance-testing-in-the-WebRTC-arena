{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_kurento_names = [\n",
    "    \"loadtest-webrtc-final-kurento-2p-t3medium\",\n",
    "    \"loadtest-webrtc-final-kurento-2p-t3medium-2\",\n",
    "    \"loadtest-webrtc-final-kurento-2p-t3medium-wait\",\n",
    "    \"loadtest-webrtc-final-kurento-2p-t3medium-retry\",\n",
    "    \"loadtest-webrtc-final-kurento-5p-t3medium\",\n",
    "    \"loadtest-webrtc-final-kurento-5p-t3medium-2\",\n",
    "    \"loadtest-webrtc-final-kurento-5p-t3medium-wait\",\n",
    "    \"loadtest-webrtc-final-kurento-5p-t3medium-retry\",\n",
    "    \"loadtest-webrtc-final-kurento-8p-t3medium\",\n",
    "    \"loadtest-webrtc-final-kurento-8p-t3medium-2\",\n",
    "    \"loadtest-webrtc-final-kurento-8p-t3medium-wait\",\n",
    "    \"loadtest-webrtc-final-kurento-8p-t3medium-retry\",\n",
    "    \"loadtest-webrtc-final-kurento-3p-10s-t3medium\",\n",
    "    \"loadtest-webrtc-final-kurento-3p-10s-t3medium-2\",\n",
    "    \"loadtest-webrtc-final-kurento-3p-10s-t3medium-wait\",\n",
    "    \"loadtest-webrtc-final-kurento-3p-10s-t3medium-retry\",\n",
    "    \"loadtest-webrtc-final-kurento-3p-20s-t3medium\",\n",
    "    \"loadtest-webrtc-final-kurento-3p-20s-t3medium-2\",\n",
    "    \"loadtest-webrtc-final-kurento-3p-20s-t3medium-wait\",\n",
    "    \"loadtest-webrtc-final-kurento-3p-20s-t3medium-retry\",\n",
    "    \"loadtest-webrtc-final-kurento-3p-40s-t3medium\",\n",
    "    \"loadtest-webrtc-final-kurento-3p-40s-t3medium-2\",\n",
    "    \"loadtest-webrtc-final-kurento-3p-40s-t3medium-wait\",\n",
    "    \"loadtest-webrtc-final-kurento-3p-40s-t3medium-retry\",\n",
    "]\n",
    "\n",
    "index_mediasoup_names = [\n",
    "    \"loadtest-webrtc-final-mediasoup-2p-t3medium\",\n",
    "    \"loadtest-webrtc-final-mediasoup-2p-t3medium-2\",\n",
    "    \"loadtest-webrtc-final-mediasoup-2p-t3medium-wait\",\n",
    "    \"loadtest-webrtc-final-mediasoup-2p-t3medium-retry\",\n",
    "    \"loadtest-webrtc-final-mediasoup-5p-t3medium\",\n",
    "    \"loadtest-webrtc-final-mediasoup-5p-t3medium-2\",\n",
    "    \"loadtest-webrtc-final-mediasoup-5p-t3medium-wait\",\n",
    "    \"loadtest-webrtc-final-mediasoup-5p-t3medium-retry\",\n",
    "    \"loadtest-webrtc-final-mediasoup-8p-t3medium\",\n",
    "    \"loadtest-webrtc-final-mediasoup-8p-t3medium-2\",\n",
    "    \"loadtest-webrtc-final-mediasoup-8p-t3medium-wait\",\n",
    "    \"loadtest-webrtc-final-mediasoup-8p-t3medium-retry\",\n",
    "    \"loadtest-webrtc-final-mediasoup-3p-10s-t3medium\",\n",
    "    \"loadtest-webrtc-final-mediasoup-3p-10s-t3medium-2\",\n",
    "    \"loadtest-webrtc-final-mediasoup-3p-10s-t3medium-wait\",\n",
    "    \"loadtest-webrtc-final-mediasoup-3p-10s-t3medium-retry\",\n",
    "    \"loadtest-webrtc-final-mediasoup-3p-20s-t3medium\",\n",
    "    \"loadtest-webrtc-final-mediasoup-3p-20s-t3medium-2\",\n",
    "    \"loadtest-webrtc-final-mediasoup-3p-20s-t3medium-wait\",\n",
    "    \"loadtest-webrtc-final-mediasoup-3p-20s-t3medium-retry\",\n",
    "    \"loadtest-webrtc-final-mediasoup-3p-40s-t3medium\",\n",
    "    \"loadtest-webrtc-final-mediasoup-3p-40s-t3medium-2\",\n",
    "    \"loadtest-webrtc-final-mediasoup-3p-40s-t3medium-wait\",\n",
    "    \"loadtest-webrtc-final-mediasoup-3p-40s-t3medium-retry\",\n",
    "]\n",
    "\n",
    "index_list_names = index_kurento_names + index_mediasoup_names\n",
    "\n",
    "node_types = [\"browseremulator\", \"masternode\", \"medianode\"]\n",
    "packet_types = [\"inbound\", \"outbound\"]\n",
    "\n",
    "seconds_per_fragment = 17\n",
    "\n",
    "start_end_times = pd.read_json(\"dfs_final/start-end-times.json\", orient=\"index\")\n",
    "start_end_times[\"from\"] = pd.to_datetime(\n",
    "    start_end_times[\"from\"], format=\"ISO8601\"\n",
    ").dt.tz_convert(\"UTC\")\n",
    "start_end_times[\"to\"] = pd.to_datetime(\n",
    "    start_end_times[\"to\"], format=\"ISO8601\"\n",
    ").dt.tz_convert(\"UTC\")\n",
    "\n",
    "\n",
    "def timestamp_to_secs(df_node, index, cpu_times=True):\n",
    "    df_tmp = df_node.copy()\n",
    "    df_tmp[\"@timestamp\"] = pd.to_datetime(df_tmp[\"@timestamp\"], format=\"ISO8601\")\n",
    "    tmp_serie = pd.Series(\n",
    "        [df_tmp[\"@timestamp\"].max(), start_end_times.loc[index, \"to\"]]\n",
    "    )\n",
    "    end_time = tmp_serie.min() if cpu_times else tmp_serie.max()\n",
    "    df_tmp = df_tmp[df_tmp[\"@timestamp\"] < end_time]\n",
    "    tmp_serie = pd.Series(\n",
    "        [df_tmp[\"@timestamp\"].min(), start_end_times.loc[index, \"from\"]]\n",
    "    )\n",
    "    start_time = tmp_serie.max() if cpu_times else tmp_serie.min()\n",
    "    df_tmp[\"timestamp_secs\"] = (df_tmp[\"@timestamp\"] - start_time).dt.total_seconds()\n",
    "    return df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [\n",
    "    pd.read_csv(f\"dfs_final/{x}.csv\")\n",
    "    if os.path.isfile(f\"dfs_final/{x}.csv\")\n",
    "    else pd.DataFrame()\n",
    "    for x in index_list_names\n",
    "]\n",
    "\n",
    "\n",
    "for i, df_user in enumerate(df_list):\n",
    "    if not df_user.empty:\n",
    "        index = index_list_names[i]\n",
    "        start_test_time = start_end_times.loc[index, \"from\"]\n",
    "\n",
    "        df_user[\"@timestamp\"] = pd.to_datetime(df_user[\"@timestamp\"], format=\"ISO8601\")\n",
    "        df_cut_index_0 = df_user[df_user[\"cut_index\"] == 0]\n",
    "        for index, row in df_cut_index_0.iterrows():\n",
    "            start_user_qoe_time = row[\"@timestamp\"]\n",
    "            time_diff = start_user_qoe_time - start_test_time\n",
    "            userFrom = row[\"userFrom\"]\n",
    "            userTo = row[\"userTo\"]\n",
    "            session = row[\"session\"]\n",
    "\n",
    "            df_user.loc[\n",
    "                (df_user[\"userFrom\"] == userFrom)\n",
    "                & (df_user[\"userTo\"] == userTo)\n",
    "                & (df_user[\"session\"] == session),\n",
    "                \"cut_index\",\n",
    "            ] = (\n",
    "                df_user.loc[\n",
    "                    (df_user[\"userFrom\"] == userFrom)\n",
    "                    & (df_user[\"userTo\"] == userTo)\n",
    "                    & (df_user[\"session\"] == session),\n",
    "                    \"cut_index\",\n",
    "                ]\n",
    "                * seconds_per_fragment\n",
    "                + time_diff.seconds\n",
    "            )\n",
    "\n",
    "index_data = []\n",
    "\n",
    "\n",
    "data_types = node_types + packet_types\n",
    "\n",
    "\n",
    "for i, df_user in enumerate(df_list):\n",
    "    index = index_list_names[i]\n",
    "\n",
    "    splitted = index.split(\"-\")\n",
    "\n",
    "    publishers = int(splitted[4][:-1])\n",
    "\n",
    "    subscribers = 0\n",
    "\n",
    "    subscribers_parsed = splitted[5]\n",
    "\n",
    "    if subscribers_parsed[-1] == \"s\":\n",
    "        subscribers = int(subscribers_parsed[:-1])\n",
    "\n",
    "    users = publishers + subscribers\n",
    "\n",
    "    repeat = 1\n",
    "\n",
    "    type = splitted[-1]\n",
    "\n",
    "    if type not in data_types:\n",
    "        if type == \"t3medium\":\n",
    "            repeat = \"1\"\n",
    "\n",
    "        else:\n",
    "            repeat = type\n",
    "\n",
    "        index_data.append(\n",
    "            {\n",
    "                \"type\": repeat,\n",
    "                \"publishers\": publishers,\n",
    "                \"subscribers\": subscribers,\n",
    "                \"users\": users,\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i, df_tmp in enumerate(df_list):\n",
    "    if not df_tmp.empty:\n",
    "        average = df_tmp[\"vmaf\"].mean()\n",
    "        median = df_tmp[\"vmaf\"].median()\n",
    "        min = df_tmp[\"vmaf\"].min()\n",
    "        max = df_tmp[\"vmaf\"].max()\n",
    "        std = df_tmp[\"vmaf\"].std()\n",
    "        data.append([index_list_names[i], average, median, std, min, max])\n",
    "\n",
    "pd.DataFrame(data, columns=[\"index_type\", \"average\", \"median\", \"std\", \"min\", \"max\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INDIVIDUAL PLOTS PARAMETERS\n",
    "\n",
    "# Index of index_list to use\n",
    "index = 45\n",
    "# If there is only one metric in display, choose which one\n",
    "metric = \"vmaf\"\n",
    "\n",
    "show_full_range = True\n",
    "\n",
    "# Calculations\n",
    "index_name = index_list_names[index]\n",
    "metric_label = metric.upper()\n",
    "qoe_metrics_normalized = [\"vmaf\", \"msssim\", \"ssim\", \"vifp\", \"pesq\", \"visqol\"]\n",
    "qoe_metrics_not_normalized = [\"psnr\", \"psnrhvs\", \"psnrhvsm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [25, 10]\n",
    "colors = [\"blue\", \"orange\", \"green\", \"red\"]\n",
    "k = 0\n",
    "\n",
    "for metric in qoe_metrics_normalized:\n",
    "    for i, df_tmp in enumerate(df_list):\n",
    "        if not df_tmp.empty:\n",
    "            if k == 0:\n",
    "                fig, ax = plt.subplots()\n",
    "            df_mean = df_tmp.groupby([\"cut_index\"]).mean(numeric_only=True)\n",
    "            plot_name = index_list_names[i]\n",
    "            if not df_mean.empty:\n",
    "                ax.plot(df_mean.index, df_mean[metric], label=plot_name)\n",
    "                ax.axvline(\n",
    "                    x=df_mean.index.max(),\n",
    "                    linestyle=\"--\",\n",
    "                    alpha=0.7,\n",
    "                )\n",
    "                ax.axvline(\n",
    "                    x=df_mean.index.min(),\n",
    "                    linestyle=\"--\",\n",
    "                    alpha=0.7,\n",
    "                )\n",
    "\n",
    "            if k == 3:\n",
    "                ax.set_xlabel(\"timestamp (seconds)\")\n",
    "                ax.set_ylabel(metric)\n",
    "                ax.grid()\n",
    "                ax.set_ylim(-0.5, 1.05)\n",
    "                ax.set_yticks(np.arange(-0.5, 1.05, 0.05))\n",
    "                fig.legend(loc=\"lower left\")\n",
    "                fig.suptitle(f\"{metric} over time (mean, {plot_name})\")\n",
    "                fig.savefig(f\"images_final/{plot_name}_{metric}.png\")\n",
    "            k = (k + 1) % 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [25, 10]\n",
    "typologies = [\"2p\", \"5p\", \"8p\", \"3p-10s\", \"3p-20s\", \"3p-40s\"]\n",
    "media_nodes = [\"kurento\", \"mediasoup\"]\n",
    "colors = [\"blue\", \"orange\", \"green\", \"red\"]\n",
    "for typology in typologies:\n",
    "    for media_node in media_nodes:\n",
    "        fig, ax = plt.subplots()\n",
    "        target_names = filter(\n",
    "            lambda x: typology in x and media_node in x, index_list_names\n",
    "        )\n",
    "\n",
    "        max_x = -1\n",
    "        for i, target_name in enumerate(target_names):\n",
    "            df_node = pd.read_csv(f\"dfs_final/{target_name}-medianode.csv\")\n",
    "            # remove entries with cpu < 0.001\n",
    "            # df_node = df_node[df_node[\"cpu\"] > 0.001]\n",
    "            df_node = timestamp_to_secs(df_node, target_name)\n",
    "            df_node = df_node.drop(columns=[\"@timestamp\", \"memory\"]).dropna()\n",
    "            ax.plot(\n",
    "                df_node[\"timestamp_secs\"],\n",
    "                df_node[\"cpu\"],\n",
    "                color=colors[i],\n",
    "                label=target_name,\n",
    "            )\n",
    "            plt.axvline(\n",
    "                x=df_node[\"timestamp_secs\"].max(),\n",
    "                color=colors[i],\n",
    "                linestyle=\"--\",\n",
    "                alpha=0.7,\n",
    "                label=\"End of test \" + target_name,\n",
    "            )\n",
    "            max_x = np.max(np.array([max_x, df_node[\"timestamp_secs\"].max()]))\n",
    "\n",
    "        ax.set_xlabel(\"timestamp (seconds)\")\n",
    "        ax.set_ylabel(\"CPU usage (%)\")\n",
    "        ax.grid()\n",
    "        ax.set_ylim(0, 1.05)\n",
    "        ax.set_yticks(np.arange(0, 1.05, 0.05))\n",
    "        # ax.set_xticks(np.arange(0, max_x, 120))\n",
    "\n",
    "        fig.suptitle(f\"CPU usage over time ({typology}, {media_node})\")\n",
    "        fig.legend(loc=\"right\")\n",
    "        fig.savefig(f\"images_final/{typology}_{media_node}_cpu.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [25, 10]\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "webrtc_stats_y = ax.twinx()\n",
    "\n",
    "aggregation_map = {\"@timestamp\": \"first\"}\n",
    "for metric in qoe_metrics_normalized:\n",
    "    aggregation_map[metric] = \"mean\"\n",
    "\n",
    "df_tmp = df_list[index].groupby(\"cut_index\").agg(aggregation_map)\n",
    "df_tmp = timestamp_to_secs(df_tmp, index_name)\n",
    "df_node = pd.read_csv(f\"dfs_final/{index_name}-medianode.csv\")\n",
    "df_node = timestamp_to_secs(df_node, index_name)\n",
    "df = df_tmp\n",
    "\n",
    "df_node_cpu = df_node.drop(columns=[\"memory\"]).dropna()\n",
    "df_node_memory = df_node.drop(columns=[\"cpu\"]).dropna()\n",
    "\n",
    "df_stats_inbound = pd.read_csv(f\"dfs_final/{index_name}-webrtc-stats-inbound.csv\")\n",
    "df_stats_outbound = pd.read_csv(f\"dfs_final/{index_name}-webrtc-stats-outbound.csv\")\n",
    "df_stats_inbound[\"@timestamp\"] = pd.to_datetime(\n",
    "    df_stats_inbound[\"@timestamp\"], format=\"ISO8601\"\n",
    ")\n",
    "df_stats_outbound[\"@timestamp\"] = pd.to_datetime(\n",
    "    df_stats_outbound[\"@timestamp\"], format=\"ISO8601\"\n",
    ")\n",
    "df_stats_inbound = df_stats_inbound.drop(columns=\"user_id\")\n",
    "df_stats_outbound = df_stats_outbound.drop(columns=\"user_id\")\n",
    "df_stats_inbound = df_stats_inbound.groupby(\"@timestamp\").mean()\n",
    "df_stats_outbound = df_stats_outbound.groupby(\"@timestamp\").mean()\n",
    "\n",
    "df_stats_inbound = timestamp_to_secs(df_stats_inbound, index_name)\n",
    "df_stats_outbound = timestamp_to_secs(df_stats_outbound, index_name)\n",
    "\n",
    "qoe_zorder = 10\n",
    "resource_zorder = 0\n",
    "\n",
    "qoe_linewidth = 3\n",
    "resource_linewidth = 1\n",
    "\n",
    "legend_handles = []\n",
    "for metric in qoe_metrics_normalized:\n",
    "    legend_handles.append(\n",
    "        ax.plot(\n",
    "            df[\"@timestamp\"],\n",
    "            df[metric],\n",
    "            label=metric,\n",
    "            marker=\"o\",\n",
    "            zorder=qoe_zorder,\n",
    "            lw=qoe_linewidth,\n",
    "        )\n",
    "    )\n",
    "legend_handles.append(\n",
    "    ax.plot(\n",
    "        df_node_cpu[\"@timestamp\"],\n",
    "        df_node_cpu[\"cpu\"],\n",
    "        \"g\",\n",
    "        label=\"cpu\",\n",
    "        zorder=resource_zorder,\n",
    "        lw=resource_linewidth,\n",
    "        linestyle=\"--\",\n",
    "    )\n",
    ")\n",
    "legend_handles.append(\n",
    "    ax.plot(\n",
    "        df_node_memory[\"@timestamp\"],\n",
    "        df_node_memory[\"memory\"],\n",
    "        \"c\",\n",
    "        label=\"memory\",\n",
    "        zorder=resource_zorder,\n",
    "        lw=resource_linewidth,\n",
    "        linestyle=\"--\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "for column in df_stats_inbound.columns[1:]:\n",
    "    # Maybe readd gpSum?\n",
    "    if (\n",
    "        not \"bytesSent\" in column\n",
    "        and not \"packetsSent\" in column\n",
    "        and not \"qpSum\" in column\n",
    "        and not \"framesEncoded\" in column\n",
    "    ):\n",
    "        legend_handles.append(\n",
    "            webrtc_stats_y.plot(\n",
    "                df_stats_inbound.index, df_stats_inbound[column], label=column\n",
    "            )\n",
    "        )\n",
    "\n",
    "ax.set_title(f\"QOE metric (normalized) over time (mean, worker data, {index_name})\")\n",
    "ax.set_xlabel(\"timestamp (day hour:minute)\")\n",
    "ax.set_ylabel(\"QOE metric (normalized), CPU %, Memory %\")\n",
    "webrtc_stats_y.set_ylabel(\"WebRTC stats\")\n",
    "ax.grid()\n",
    "ax.legend(loc=\"upper left\")\n",
    "webrtc_stats_y.legend(loc=\"center left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"results_all\", exist_ok=True)\n",
    "\n",
    "df_tmp = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "X = df_tmp[\"user_count\"]\n",
    "\n",
    "\n",
    "X = sm.add_constant(X)  # adding a constant\n",
    "\n",
    "metrics = qoe_metrics_normalized + qoe_metrics_not_normalized\n",
    "\n",
    "for metric in metrics:\n",
    "    Y = df_tmp[metric]\n",
    "\n",
    "    model = sm.OLS(Y, X).fit()\n",
    "    summary = model.summary()\n",
    "\n",
    "    with open(f\"results_all/{metric}-all-summary.tex\", \"w\") as fh:\n",
    "        fh.write(summary.as_latex())\n",
    "\n",
    "    with open(f\"results_all/{metric}-all-summary.html\", \"w\") as fh:\n",
    "        fh.write(summary.as_html())\n",
    "\n",
    "    with open(f\"results_all/{metric}-all.txt\", \"w\") as fh:\n",
    "        fh.write(summary.as_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"results_kurento\", exist_ok=True)\n",
    "\n",
    "df_tmp = pd.concat(df_list[:24], ignore_index=True)\n",
    "\n",
    "X = df_tmp[\"user_count\"]\n",
    "\n",
    "X = sm.add_constant(X)  # adding a constant\n",
    "\n",
    "for metric in metrics:\n",
    "    Y = df_tmp[metric]\n",
    "\n",
    "    model = sm.OLS(Y, X).fit()\n",
    "    summary = model.summary()\n",
    "\n",
    "    with open(f\"results_kurento/{metric}-kurento-summary.tex\", \"w\") as fh:\n",
    "        fh.write(summary.as_latex())\n",
    "\n",
    "    with open(f\"results_kurento/{metric}-kurento-summary.html\", \"w\") as fh:\n",
    "        fh.write(summary.as_html())\n",
    "\n",
    "    with open(f\"results_kurento/{metric}-kurento.txt\", \"w\") as fh:\n",
    "        fh.write(summary.as_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"results_mediasoup\", exist_ok=True)\n",
    "\n",
    "df_tmp = pd.concat(df_list[24:], ignore_index=True)\n",
    "\n",
    "X = df_tmp[\"user_count\"]\n",
    "\n",
    "X = sm.add_constant(X)  # adding a constant\n",
    "\n",
    "for metric in metrics:\n",
    "    Y = df_tmp[metric]\n",
    "\n",
    "    model = sm.OLS(Y, X).fit()\n",
    "    summary = model.summary()\n",
    "\n",
    "    with open(f\"results_mediasoup/{metric}-mediasoup-summary.tex\", \"w\") as fh:\n",
    "        fh.write(summary.as_latex())\n",
    "\n",
    "    with open(f\"results_mediasoup/{metric}-mediasoup-summary.html\", \"w\") as fh:\n",
    "        fh.write(summary.as_html())\n",
    "\n",
    "    with open(f\"results_mediasoup/{metric}-mediasoup.txt\", \"w\") as fh:\n",
    "        fh.write(summary.as_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_list = []\n",
    "for i, df_tmp in enumerate(df_list):\n",
    "    index_name = index_list_names[i]\n",
    "    df_node = pd.read_csv(f\"dfs_final/{index_name}-medianode.csv\")\n",
    "    df_node = df_node.drop(columns=[\"memory\"]).dropna()\n",
    "    df_tmp = timestamp_to_secs(df_tmp, index_name, False)\n",
    "    df_node = timestamp_to_secs(df_node, index_name, False)\n",
    "    df_tmp[\"timestamp_secs\"] = df_tmp[\"timestamp_secs\"].round(-1)\n",
    "    df_node[\"timestamp_secs\"] = df_node[\"timestamp_secs\"].round(-1)\n",
    "    df_tmp = df_tmp.groupby([\"timestamp_secs\"]).mean(numeric_only=True)\n",
    "\n",
    "    merged_df = pd.merge(df_tmp, df_node, on=\"timestamp_secs\", how=\"inner\")\n",
    "\n",
    "    df_merged_list.append(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"results_all_cpu\", exist_ok=True)\n",
    "\n",
    "df_tmp = pd.concat(df_merged_list, ignore_index=True)\n",
    "\n",
    "X = df_tmp[\"cpu\"]\n",
    "\n",
    "\n",
    "X = sm.add_constant(X)  # adding a constant\n",
    "\n",
    "metrics = qoe_metrics_normalized + qoe_metrics_not_normalized\n",
    "\n",
    "for metric in metrics:\n",
    "    Y = df_tmp[metric]\n",
    "\n",
    "    model = sm.OLS(Y, X).fit()\n",
    "    summary = model.summary()\n",
    "\n",
    "    with open(f\"results_all_cpu/{metric}-all-summary.tex\", \"w\") as fh:\n",
    "        fh.write(summary.as_latex())\n",
    "\n",
    "    with open(f\"results_all_cpu/{metric}-all-summary.html\", \"w\") as fh:\n",
    "        fh.write(summary.as_html())\n",
    "\n",
    "    with open(f\"results_all_cpu/{metric}-all.txt\", \"w\") as fh:\n",
    "        fh.write(summary.as_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"results_kurento_cpu\", exist_ok=True)\n",
    "\n",
    "df_tmp = pd.concat(df_merged_list[:24], ignore_index=True)\n",
    "X = df_tmp[\"cpu\"]\n",
    "\n",
    "\n",
    "X = sm.add_constant(X)  # adding a constant\n",
    "\n",
    "metrics = qoe_metrics_normalized + qoe_metrics_not_normalized\n",
    "\n",
    "for metric in metrics:\n",
    "    Y = df_tmp[metric]\n",
    "\n",
    "    model = sm.OLS(Y, X).fit()\n",
    "    summary = model.summary()\n",
    "\n",
    "    with open(f\"results_kurento_cpu/{metric}-kurento-summary.tex\", \"w\") as fh:\n",
    "        fh.write(summary.as_latex())\n",
    "\n",
    "    with open(f\"results_kurento_cpu/{metric}-kurento-summary.html\", \"w\") as fh:\n",
    "        fh.write(summary.as_html())\n",
    "\n",
    "    with open(f\"results_kurento_cpu/{metric}-kurento.txt\", \"w\") as fh:\n",
    "        fh.write(summary.as_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"results_mediasoup_cpu\", exist_ok=True)\n",
    "\n",
    "df_tmp = pd.concat(df_merged_list[24:], ignore_index=True)\n",
    "\n",
    "X = df_tmp[\"cpu\"]\n",
    "\n",
    "X = sm.add_constant(X)  # adding a constant\n",
    "\n",
    "for metric in metrics:\n",
    "    Y = df_tmp[metric]\n",
    "\n",
    "    model = sm.OLS(Y, X).fit()\n",
    "    summary = model.summary()\n",
    "\n",
    "    with open(f\"results_mediasoup_cpu/{metric}-mediasoup-summary.tex\", \"w\") as fh:\n",
    "        fh.write(summary.as_latex())\n",
    "\n",
    "    with open(f\"results_mediasoup_cpu/{metric}-mediasoup-summary.html\", \"w\") as fh:\n",
    "        fh.write(summary.as_html())\n",
    "\n",
    "    with open(f\"results_mediasoup_cpu/{metric}-mediasoup.txt\", \"w\") as fh:\n",
    "        fh.write(summary.as_text())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
